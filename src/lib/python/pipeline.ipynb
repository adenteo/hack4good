{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('activity.csv').to_json(orient='records')\n",
    "# postal = pd.read_csv('SG_postal.csv')\n",
    "# activity_df = df.merge(postal, left_on='postalCode', right_on='postal_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demographics_report(data, timeframe='monthly'):\n",
    "    # Load data\n",
    "    activity_df = pd.read_json(data)\n",
    "\n",
    "    zones = pd.DataFrame({\n",
    "    \"Zone\": [\"City\", \"City\", \"South\", \"South\", \"West\", \"City\", \"City\", \"Central\", \"Central\", \"Central\", \n",
    "             \"Central\", \"Central\", \"East\", \"East\", \"East\", \"East\", \"East\", \"East\", \"North\", \"North\",\n",
    "             \"West\", \"West\", \"West\", \"West\", \"North\", \"North\", \"North\", \"North\"],\n",
    "    \"District\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
    "    \"PostalBeginsWith\": [\n",
    "        \"01, 02, 03, 04, 05, 06\", \"07, 08\", \"14, 15, 16\", \"09, 10\", \"11, 12, 13\", \"17\", \"18, 19\", \n",
    "        \"20, 21\", \"22, 23\", \"24, 25, 26, 27\", \"28, 29, 30\", \"31, 32, 33\", \"34, 35, 36, 37\", \"38, 39, 40, 41\",\n",
    "        \"42, 43, 44, 45\", \"46, 47, 48\", \"49, 50, 81\", \"51, 52\", \"53, 54, 55, 82\", \"56, 57\", \"58, 59\", \n",
    "        \"60, 61, 62, 63, 64\", \"65, 66, 67, 68\", \"69, 70, 71\", \"72, 73\", \"77, 78\", \"75, 76\", \"79, 80\"\n",
    "    ]})\n",
    "    # Extract the first two digits for mapping\n",
    "    zones['PostalBeginsWith'] = zones['PostalBeginsWith'].apply(lambda x: [y[:2] for y in x.split(', ')])\n",
    "    zones_exploded = zones.explode('PostalBeginsWith')\n",
    "\n",
    "    activity_df['startTime'] = pd.to_datetime(activity_df['startTime'])\n",
    "    activity_df['day'] = activity_df['startTime'].dt.day\n",
    "    activity_df['year'] = activity_df['startTime'].dt.year\n",
    "    activity_df['month'] = activity_df['startTime'].dt.month\n",
    "    activity_df['quarter'] = activity_df['startTime'].dt.quarter\n",
    "    activity_df['postalCodeFirstTwo'] = activity_df['postalCode'].astype(str).str.zfill(6).str[:2]\n",
    "    activity_df = activity_df.merge(zones_exploded, how='left', left_on='postalCodeFirstTwo', right_on='PostalBeginsWith')\n",
    "    activity_df['rowCount'] = 1\n",
    "\n",
    "\n",
    "    # Convert boolean columns to integer type\n",
    "    activity_df['drivingLicence'] = activity_df['drivingLicence'].astype(int)\n",
    "    activity_df['pwdTrained'] = activity_df['pwdTrained'].astype(int)\n",
    "\n",
    "    # Get dummies for categorical columns\n",
    "    attendance_dummies = pd.get_dummies(activity_df['attendanceStatus'], prefix='attendance')\n",
    "    tags_dummies = activity_df['tags'].str.get_dummies(sep=',')\n",
    "    citizenship_dummies = pd.get_dummies(activity_df['citizenshipType'], prefix='citizenship')\n",
    "    employment_dummies = pd.get_dummies(activity_df['employmentStatus'], prefix='employment')\n",
    "    gender_dummies = pd.get_dummies(activity_df['gender'], prefix='gender')\n",
    "    zone_dummies = pd.get_dummies(activity_df['Zone'], prefix='zone')\n",
    "\n",
    "    current_year = pd.Timestamp('now').year\n",
    "    activity_df['dateOfBirth'] = pd.to_datetime(activity_df['dateOfBirth'])\n",
    "    activity_df['age'] = current_year - activity_df['dateOfBirth'].dt.year\n",
    "\n",
    "    # Group age into categories and get dummies\n",
    "    bins = [0, 13, 21, 50, 65, float('inf')]\n",
    "    labels = ['under13', 'under21', 'under50', 'under65', 'over65']\n",
    "    activity_df['ageGroup'] = pd.cut(activity_df['age'], bins=bins, labels=labels, right=False)\n",
    "    age_group_dummies = pd.get_dummies(activity_df['ageGroup'])\n",
    "\n",
    "    # Concatenate all dummies and the original DataFrame (excluding original categorical columns)\n",
    "    final_df = pd.concat([\n",
    "        activity_df.drop(['attendanceStatus','tags', 'citizenshipType', 'employmentStatus', 'gender', 'age', 'ageGroup', 'Zone'], axis=1),\n",
    "        attendance_dummies, tags_dummies, citizenship_dummies, employment_dummies, gender_dummies, age_group_dummies, zone_dummies\n",
    "    ], axis=1)\n",
    "\n",
    "    # Group by year and month, and sum the numHours and other one-hot encoded columns\n",
    "    if timeframe == 'annual':\n",
    "        final_df = final_df.groupby(['year'])\n",
    "    elif timeframe == 'quarterly':\n",
    "        final_df = final_df.groupby(['year', 'quarter'])\n",
    "    elif timeframe == 'monthly':\n",
    "        final_df = final_df.groupby(['year', 'month'])\n",
    "    elif timeframe == 'daily':\n",
    "        final_df = final_df.groupby(['year', 'month', 'day'])\n",
    "    else:\n",
    "        raise ValueError('Invalid timeframe')\n",
    "\n",
    "    summary = final_df.agg({\n",
    "        'rowCount': 'count', #count number of records\n",
    "        'numHours': 'sum',  # Sum numHours for total hours\n",
    "        **{col: 'sum' for col in attendance_dummies.columns},  # Sum for each attendance status\n",
    "        **{col: 'sum' for col in tags_dummies.columns},  # Sum for each tag column\n",
    "        'drivingLicence': 'sum',\n",
    "        'pwdTrained': 'sum',\n",
    "        **{col: 'sum' for col in citizenship_dummies.columns},  # Sum for each citizenship status\n",
    "        **{col: 'sum' for col in employment_dummies.columns},  # Sum for each employment status\n",
    "        **{col: 'sum' for col in gender_dummies.columns},  # Sum for each gender\n",
    "        **{col: 'sum' for col in age_group_dummies.columns},  # Sum for each age group\n",
    "        **{col: 'sum' for col in zone_dummies.columns},  # Sum for each zone\n",
    "    }).reset_index()\n",
    "\n",
    "    return summary#.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_demographics_report(df, 'monthly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_attendance_report(user_ids, data, timeframe='monthly'):\n",
    "    # Load data\n",
    "    activity_df = pd.read_json(data)\n",
    "\n",
    "    # Filter DataFrame for the given user IDs\n",
    "    activity_df = activity_df[activity_df['userId'].isin(user_ids)]\n",
    "    \n",
    "    user_details_columns = ['userId', 'fullName', 'employmentStatus', 'contactNumber', 'gender', \n",
    "                            'occupation', 'skills', 'declarations', 'drivingLicence', 'address', \n",
    "                            'pwdTrained', 'dateOfBirth']\n",
    "    user_details_df = activity_df[user_details_columns].drop_duplicates(subset=['userId'])\n",
    "    # Calculate age from dateOfBirth\n",
    "    current_year = datetime.now().year\n",
    "    user_details_df['dateOfBirth'] = pd.to_datetime(user_details_df['dateOfBirth'])\n",
    "    user_details_df['age'] = current_year - user_details_df['dateOfBirth'].dt.year\n",
    "\n",
    "    # Ensure startTime is in datetime format\n",
    "    activity_df['startTime'] = pd.to_datetime(activity_df['startTime'])\n",
    "    activity_df['year'] = activity_df['startTime'].dt.year\n",
    "    activity_df['month'] = activity_df['startTime'].dt.month\n",
    "    activity_df['quarter'] = activity_df['startTime'].dt.quarter\n",
    "    activity_df['day'] = activity_df['startTime'].dt.day\n",
    "\n",
    "    # Convert attendanceStatus to dummies\n",
    "    attendance_status_dummies = pd.get_dummies(activity_df['attendanceStatus'], prefix='attendanceStatus')\n",
    "\n",
    "    # Get dummies for tags\n",
    "    tags_dummies = activity_df['tags'].str.get_dummies(sep=',')\n",
    "\n",
    "    # Add a row count column for counting the number of events signed up\n",
    "    activity_df['eventSignUpCount'] = 1\n",
    "\n",
    "    # Concatenate dummies and the original DataFrame\n",
    "    activity_df = pd.concat([\n",
    "        activity_df[['userId', 'year', 'month', 'quarter', 'day', 'numHours', 'eventSignUpCount']],\n",
    "        attendance_status_dummies,\n",
    "        tags_dummies\n",
    "    ], axis=1)\n",
    "\n",
    "    # Define group by columns based on timeframe\n",
    "    group_by_columns = ['userId', 'year', 'month', 'quarter', 'day']\n",
    "    if timeframe == 'annual':\n",
    "        group_by_columns = ['userId', 'year']\n",
    "    elif timeframe == 'quarterly':\n",
    "        group_by_columns = ['userId', 'year', 'quarter']\n",
    "    elif timeframe == 'monthly':\n",
    "        group_by_columns = ['userId', 'year', 'month']\n",
    "    elif timeframe == 'daily':\n",
    "        group_by_columns = ['userId', 'year', 'month', 'day']\n",
    "    else:\n",
    "        raise ValueError('Invalid timeframe specified')\n",
    "\n",
    "    # Group by and summarize\n",
    "    grouped_df = activity_df.groupby(group_by_columns).agg({\n",
    "        'eventSignUpCount': 'sum',\n",
    "        'numHours': 'sum',\n",
    "        **{col: 'sum' for col in attendance_status_dummies.columns},\n",
    "        **{col: 'sum' for col in tags_dummies.columns},\n",
    "    }).reset_index()\n",
    "\n",
    "    return grouped_df, user_details_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_users = [\"65c1c5f0919469d96a250701\", \"65c1c5a1919469d96a24fdb5\", \"65c1c5fc919469d96a25088d\", \"65c1c5d7919469d96a2503f9\"]\n",
    "output2 = get_attendance_report(example_users, df, 'daily')[0]\n",
    "output3 = get_attendance_report(example_users, df, 'daily')[1]\n",
    "output2.to_csv('attendance_report.csv', index=False)\n",
    "output3.to_csv('user_details.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>fullName</th>\n",
       "      <th>employmentStatus</th>\n",
       "      <th>contactNumber</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>skills</th>\n",
       "      <th>declarations</th>\n",
       "      <th>drivingLicence</th>\n",
       "      <th>address</th>\n",
       "      <th>pwdTrained</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65c1c5f0919469d96a250701</td>\n",
       "      <td>Cornelius Metz-Kohler</td>\n",
       "      <td>Student</td>\n",
       "      <td>90059</td>\n",
       "      <td>Female</td>\n",
       "      <td>Corporate Data Analyst</td>\n",
       "      <td>innocent versus oh butler paragraph</td>\n",
       "      <td>Ager pauper autem currus vivo eius asperiores ...</td>\n",
       "      <td>False</td>\n",
       "      <td>7688 Prosacco Mission</td>\n",
       "      <td>False</td>\n",
       "      <td>2000-02-25 11:36:59.732000+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65c1c5fc919469d96a25088d</td>\n",
       "      <td>Mallory Gleason</td>\n",
       "      <td>Student</td>\n",
       "      <td>23808</td>\n",
       "      <td>Other</td>\n",
       "      <td>National Program Engineer</td>\n",
       "      <td>yowza that aha quickly couch</td>\n",
       "      <td>Utique coerceo avarus alius collum vitiosus ad...</td>\n",
       "      <td>False</td>\n",
       "      <td>215 Maple Avenue</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-29 14:20:08.036000+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>65c1c5d7919469d96a2503f9</td>\n",
       "      <td>Keyshawn Friesen</td>\n",
       "      <td>Employed / Self- Employed</td>\n",
       "      <td>72103</td>\n",
       "      <td>Other</td>\n",
       "      <td>Principal Metrics Executive</td>\n",
       "      <td>anenst eventually modulo scheme likewise</td>\n",
       "      <td>Victus statim vulariter sublime supra dolorem ...</td>\n",
       "      <td>True</td>\n",
       "      <td>20917 Grange Avenue</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-12-13 17:43:55.279000+00:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>65c1c5a1919469d96a24fdb5</td>\n",
       "      <td>Neoma Connelly</td>\n",
       "      <td>Student</td>\n",
       "      <td>72318</td>\n",
       "      <td>Female</td>\n",
       "      <td>Chief Directives Assistant</td>\n",
       "      <td>adsorb apparel sick the easy</td>\n",
       "      <td>Tertius degero vilitas bonus conculco aptus.</td>\n",
       "      <td>True</td>\n",
       "      <td>7403 Rosalind Station</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-10-15 22:52:12.813000+00:00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       userId               fullName  \\\n",
       "8    65c1c5f0919469d96a250701  Cornelius Metz-Kohler   \n",
       "16   65c1c5fc919469d96a25088d        Mallory Gleason   \n",
       "42   65c1c5d7919469d96a2503f9       Keyshawn Friesen   \n",
       "162  65c1c5a1919469d96a24fdb5         Neoma Connelly   \n",
       "\n",
       "              employmentStatus  contactNumber  gender  \\\n",
       "8                      Student          90059  Female   \n",
       "16                     Student          23808   Other   \n",
       "42   Employed / Self- Employed          72103   Other   \n",
       "162                    Student          72318  Female   \n",
       "\n",
       "                      occupation                                    skills  \\\n",
       "8         Corporate Data Analyst       innocent versus oh butler paragraph   \n",
       "16     National Program Engineer              yowza that aha quickly couch   \n",
       "42   Principal Metrics Executive  anenst eventually modulo scheme likewise   \n",
       "162   Chief Directives Assistant              adsorb apparel sick the easy   \n",
       "\n",
       "                                          declarations  drivingLicence  \\\n",
       "8    Ager pauper autem currus vivo eius asperiores ...           False   \n",
       "16   Utique coerceo avarus alius collum vitiosus ad...           False   \n",
       "42   Victus statim vulariter sublime supra dolorem ...            True   \n",
       "162       Tertius degero vilitas bonus conculco aptus.            True   \n",
       "\n",
       "                   address  pwdTrained                      dateOfBirth  age  \n",
       "8    7688 Prosacco Mission       False 2000-02-25 11:36:59.732000+00:00   24  \n",
       "16        215 Maple Avenue        True 2017-01-29 14:20:08.036000+00:00    7  \n",
       "42     20917 Grange Avenue        True 2004-12-13 17:43:55.279000+00:00   20  \n",
       "162  7403 Rosalind Station       False 2005-10-15 22:52:12.813000+00:00   19  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_09ef41a97ecd5651460b8f8c6a823096 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium@main/folium/templates/leaflet_heat.min.js&quot;&gt;&lt;/script&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_09ef41a97ecd5651460b8f8c6a823096&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_09ef41a97ecd5651460b8f8c6a823096 = L.map(\n",
       "                &quot;map_09ef41a97ecd5651460b8f8c6a823096&quot;,\n",
       "                {\n",
       "                    center: [1.3408571428571427, 103.84011607142858],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 12,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_f764b3141052d3b3be523d02a33e43f0 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_f764b3141052d3b3be523d02a33e43f0.addTo(map_09ef41a97ecd5651460b8f8c6a823096);\n",
       "        \n",
       "    \n",
       "            var heat_map_292a2413bfd19247e69417604f631496 = L.heatLayer(\n",
       "                [[1.2802, 103.7884, 3.0], [1.2803, 103.842, 8.0], [1.2927, 103.8043, 1.0], [1.2953, 103.7674, 3.0], [1.2992, 103.8155, 2.0], [1.3088, 103.924, 6.0], [1.3133, 103.877, 4.0], [1.3133, 103.8982, 1.0], [1.3136, 103.904, 3.0], [1.3151, 103.9119, 4.0], [1.3155, 103.8407, 4.0], [1.3165, 103.7526, 5.0], [1.3169, 103.8091, 2.0], [1.3182, 103.9089, 3.0], [1.3188, 103.9243, 3.0], [1.32, 103.7869, 1.0], [1.3208, 103.9202, 1.0], [1.3208, 103.948, 3.0], [1.3229, 103.6351, 1.0], [1.3241, 103.9562, 5.0], [1.327, 103.7909, 4.0], [1.3297, 103.6519, 2.0], [1.3336, 103.7038, 2.0], [1.3362, 103.7862, 1.0], [1.3363, 103.7657, 9.0], [1.3376, 103.9254, 5.0], [1.3428, 103.8728, 4.0], [1.3455, 103.8799, 1.0], [1.3473, 103.8851, 4.0], [1.3485, 103.7883, 2.0], [1.3532, 103.8451, 1.0], [1.355, 103.7596, 3.0], [1.3572, 103.866, 5.0], [1.3644, 103.8833, 3.0], [1.3647, 103.9747, 5.0], [1.3652, 103.7713, 1.0], [1.373, 103.7734, 7.0], [1.3776, 103.9577, 3.0], [1.3777, 103.8309, 3.0], [1.3778, 103.8355, 1.0], [1.3797, 103.8365, 3.0], [1.3816, 103.947, 4.0], [1.3821, 103.8639, 1.0], [1.3892, 103.8541, 3.0], [1.4033, 103.8136, 7.0], [1.4169, 103.8465, 1.0], [1.4179, 103.8469, 4.0]],\n",
       "                {&quot;blur&quot;: 15, &quot;maxZoom&quot;: 18, &quot;minOpacity&quot;: 0.5, &quot;radius&quot;: 25}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            heat_map_292a2413bfd19247e69417604f631496.addTo(map_09ef41a97ecd5651460b8f8c6a823096);\n",
       "        \n",
       "    \n",
       "            tile_layer_f764b3141052d3b3be523d02a33e43f0.addTo(map_09ef41a97ecd5651460b8f8c6a823096);\n",
       "        \n",
       "    \n",
       "            heat_map_292a2413bfd19247e69417604f631496.addTo(map_09ef41a97ecd5651460b8f8c6a823096);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x13c2204d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install folium\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import pandas as pd\n",
    "\n",
    "df = activity_df\n",
    "# Create a map centered around the average latitude and longitude\n",
    "map_center_lat = df['lat'].mean()\n",
    "map_center_lon = df['lon'].mean()\n",
    "volunteer_map = folium.Map(location=[map_center_lat, map_center_lon], zoom_start=12)\n",
    "\n",
    "# Aggregate hours by location\n",
    "location_hours = df.groupby(['lat', 'lon'])['numHours'].sum().reset_index()\n",
    "\n",
    "# Create a list of lists where each inner list contains the latitude, longitude, and weight (hours)\n",
    "heat_data = [[row['lat'], row['lon'], row['numHours']] for index, row in location_hours.iterrows()]\n",
    "\n",
    "# Create a heat map layer and add it to the map\n",
    "HeatMap(heat_data).add_to(volunteer_map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "volunteer_map.save('volunteer_hours_distribution_map.html')\n",
    "\n",
    "# Display the map in a Jupyter notebook (if you're using one, otherwise the map will be saved to the HTML file)\n",
    "volunteer_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output.to_csv('monthly_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from numpy import int64\n",
    "monthly_summary = pd.read_csv('monthly_summary.csv')\n",
    "json_data = monthly_summary.to_json(orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to select a row based on year and month and format the output with grouped categories\n",
    "def get_month_summary_grouped(data, year, month):\n",
    "    # Convert the JSON data to a dataframe\n",
    "    df = pd.DataFrame(json.loads(data))\n",
    "    \n",
    "    # Select the row for the given year and month\n",
    "    selected_row = df[(df['year'] == year) & (df['month'] == month)]\n",
    "    \n",
    "    # If no matching row found, return a message\n",
    "    if selected_row.empty:\n",
    "        return \"No data found for the specified year and month.\"\n",
    "    \n",
    "    # Convert numpy.int64 to int for JSON serialization\n",
    "    def convert_int64(val):\n",
    "        return int(val) if isinstance(val, int64) else val\n",
    "\n",
    "    # Dictionary to hold the grouped categories\n",
    "    grouped_categories = {\n",
    "        'Year': convert_int64(selected_row['year'].values[0]),\n",
    "        'Month': convert_int64(selected_row['month'].values[0]),\n",
    "        'Number of Activities': convert_int64(selected_row['rowCount'].values[0]),\n",
    "        'Total Hours': convert_int64(selected_row['numHours'].values[0]),\n",
    "        'Skills': selected_row[['drivingLicence', 'pwdTrained']].applymap(convert_int64).to_dict('records')[0],\n",
    "        'Attendance': selected_row.filter(regex='attendance_').applymap(convert_int64).to_dict('records')[0],\n",
    "        'Theme Prevalence': selected_row.iloc[:, 7:33].applymap(convert_int64).to_dict('records')[0],\n",
    "        'Citizenship': selected_row.filter(regex='citizenship_').applymap(convert_int64).to_dict('records')[0],\n",
    "        'Employment': selected_row.filter(regex='employment_').applymap(convert_int64).to_dict('records')[0],\n",
    "        'Gender': selected_row.filter(regex='gender_').applymap(convert_int64).to_dict('records')[0],\n",
    "        'AgeGroups': selected_row.filter(regex='^under|^over').applymap(convert_int64).to_dict('records')[0],\n",
    "        'Zones': selected_row.filter(regex='zone_').applymap(convert_int64).to_dict('records')[0]\n",
    "    }\n",
    "    \n",
    "    # Convert the grouped categories dictionary to JSON\n",
    "    return grouped_categories\n",
    "\n",
    "# Example usage:\n",
    "# Assume we want to get the summary for March 2022\n",
    "example_year = 2022\n",
    "example_month = 3\n",
    "output = get_month_summary_grouped(json_data, example_year, example_month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
